import os
import json
import torch
import argparse
import pickle
import numpy as np
import pprint as pp
import torch.nn.functional as F

from torch_geometric.data import Batch, Data

from .problems.shopping import Shopping
from .nets.attention_model import AttentionModel, set_decode_type
from .train import get_inner_model
from .utils import torch_load_cpu, move_to

def _create_subgraph_from_labels(full_data, node_labels_to_extract, start_node_label, device):
    """
    [ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜]
    ì „ì²´ ê·¸ë˜í”„ ë°ì´í„°ì—ì„œ ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë…¸ë“œë“¤ë§Œ ì¶”ì¶œí•˜ê³ ,
    ì§€ì •ëœ ì‹œì‘ ë…¸ë“œë¥¼ ì„¤ì •í•˜ì—¬ ìƒˆë¡œìš´ PyG Data ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print(f"\n  [INFO] {len(node_labels_to_extract)}ê°œì˜ ë…¸ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ì„œë¸Œê·¸ë˜í”„ ìƒì„± ì¤‘...")
    
    label_to_idx = full_data['label_to_idx']
    try:
        indices = [label_to_idx[label] for label in node_labels_to_extract]
    except KeyError as e:
        print(f"  [ì˜¤ë¥˜] ë ˆì´ë¸” '{e.args[0]}'ë¥¼ ì „ì²´ ê·¸ë˜í”„('full_data')ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    N_sub = len(indices)
    
    sub_dist_mat = full_data['dist_matrix'][np.ix_(indices, indices)]
    sub_coords = full_data['node_coords'][indices]

    try:
        # 1. ì¢…ë£Œ ë…¸ë“œëŠ” .pkl íŒŒì¼ì˜ ê¸°ë³¸ê°’ì„ ì‚¬ìš©
        end_label = full_data['labels'][full_data['default_end_idx']]
        sub_end_idx = node_labels_to_extract.index(end_label)
        
        # 2. ì‹œì‘ ë…¸ë“œëŠ” í•¨ìˆ˜ ì¸ìë¡œ ë°›ì€ 'start_node_label'ì„ ì‚¬ìš©
        if start_node_label not in node_labels_to_extract:
            raise ValueError(f"ì§€ì •í•œ ì‹œì‘ ë…¸ë“œ '{start_node_label}'ê°€ ì‡¼í•‘ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        sub_start_idx = node_labels_to_extract.index(start_node_label)
        
    except (ValueError, TypeError, KeyError) as e:
        print(f"  [ì˜¤ë¥˜] ì‹œì‘/ì¢…ë£Œ ë…¸ë“œ ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

    dist_mat_torch = torch.FloatTensor(sub_dist_mat).to(device)
    
    adj = torch.ones((N_sub, N_sub)) - torch.eye(N_sub)
    edge_index = adj.nonzero(as_tuple=False).t().contiguous().to(device)
    edge_attr = dist_mat_torch[edge_index[0], edge_index[1]].unsqueeze(1)
    
    data = Data(
        edge_index=edge_index, edge_attr=edge_attr, dist_matrix=dist_mat_torch,
        node_coords=torch.FloatTensor(sub_coords).to(device),
        start_idx=torch.tensor(sub_start_idx, dtype=torch.long).to(device),
        end_idx=torch.tensor(sub_end_idx, dtype=torch.long).to(device),
        num_nodes=N_sub
    )
    return data

def get_shopping_route(load_path, full_graph_path, shopping_list, start_node_label, num_samples, use_cuda=True):
    """
    AI ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , ì£¼ì–´ì§„ ì‡¼í•‘ ë¦¬ìŠ¤íŠ¸ì™€ 'ì‹œì‘ ë…¸ë“œ'ì— ëŒ€í•œ ìµœì ì˜ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        load_path (str): í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸(.pt) íŒŒì¼ ê²½ë¡œ
        full_graph_path (str): ì „ì²´ ìµœë‹¨ ê±°ë¦¬ ê·¸ë˜í”„ íŒŒì¼ (.pkl)
        shopping_list (list): ['S1', 'T1', 'T5', ..., 'E1'] í˜•íƒœì˜ ë…¸ë“œ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸
        start_node_label (str): ê²½ë¡œì˜ ì‹œì‘ì ì´ ë  ë…¸ë“œì˜ ë ˆì´ë¸” (ì˜ˆ: 'S1' ë˜ëŠ” 'T5')
        num_samples (int): í•´ë¥¼ íƒìƒ‰í•  ìƒ˜í”Œë§ íšŸìˆ˜ (k)
        use_cuda (bool): CUDA ì‚¬ìš© ì—¬ë¶€

    Returns:
        list: [start_node_label, ..., 'E1'] í˜•íƒœì˜ ìµœì  ë…¸ë“œ ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    
    print("--- ğŸ¤– AI Solver ì‹œì‘ ---")
    device = torch.device("cuda:0" if use_cuda else "cpu")

    # --- 1. í›ˆë ¨ ë‹¹ì‹œì˜ ì„¤ì •(opts) ë¶ˆëŸ¬ì˜¤ê¸° ---
    load_dir = os.path.dirname(load_path)
    args_json_path = os.path.join(load_dir, "args.json")
    
    if not os.path.exists(args_json_path):
        print(f"  [ì˜¤ë¥˜] {args_json_path} ì—ì„œ args.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None
        
    print(f"  [INFO] {args_json_path} ì—ì„œ í›ˆë ¨ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
    with open(args_json_path, 'r') as f:
        train_opts_dict = json.load(f)
    
    opts = argparse.Namespace(**train_opts_dict)
    opts.device = device

    # --- 2. ëª¨ë¸ ë¡œë“œ (ë‹¨ í•œë²ˆ) ---
    print(f"  [INFO] {load_path} ì—ì„œ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    problem = Shopping()
    problem.size = opts.graph_size 
    
    model = AttentionModel(
        embedding_dim=opts.embedding_dim, hidden_dim=opts.hidden_dim,
        problem=problem, n_encode_layers=opts.n_encode_layers,
        n_heads=opts.n_heads, tanh_clipping=opts.tanh_clipping,
        latent_dim=opts.latent_dim
    ).to(opts.device)
    
    load_data = torch_load_cpu(load_path)
    get_inner_model(model).load_state_dict(load_data['model'])
    model.eval()
    print("  [INFO] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    # --- 3. ì „ì²´ ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ (ë‹¨ í•œë²ˆ) ---
    print(f"  [INFO] {full_graph_path} ì—ì„œ ì „ì²´ ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        with open(full_graph_path, 'rb') as f:
            full_data = pickle.load(f)
    except Exception as e:
        print(f"  [ì˜¤ë¥˜] ì „ì²´ ê·¸ë˜í”„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    print("  [INFO] ì „ì²´ ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ.")

    # --- 4. ì…ë ¥ëœ ì •ë³´ë¡œ PyG ì¸ìŠ¤í„´ìŠ¤(ì„œë¸Œê·¸ë˜í”„) ìƒì„± ---
    instance = _create_subgraph_from_labels(
        full_data, 
        shopping_list, 
        start_node_label, # âœ… ì§€ì •ëœ ì‹œì‘ ë…¸ë“œ ì „ë‹¬
        opts.device
    )
    if instance is None:
        return None

    if instance.num_nodes != opts.graph_size:
         print(f"  [ê²½ê³ ] ëª¨ë¸ì€ {opts.graph_size} ë…¸ë“œë¡œ í›ˆë ¨ë˜ì—ˆìœ¼ë‚˜, "
               f"ì…ë ¥ëœ ì¸ìŠ¤í„´ìŠ¤ëŠ” {instance.num_nodes}ê°œì˜ ë…¸ë“œë¥¼ ê°€ì§‘ë‹ˆë‹¤.")
         get_inner_model(model).problem.size = instance.num_nodes

    # --- 5. MP-ASIL ìƒ˜í”Œë§ìœ¼ë¡œ ìµœê³ ì˜ í•´ íƒìƒ‰ ---
    print(f"  [INFO] {num_samples}ë²ˆì˜ ìƒ˜í”Œë§ìœ¼ë¡œ ìµœê³ ì˜ í•´ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤...")
    set_decode_type(get_inner_model(model), "sampling", temp=1.0)
    
    B = 1; k = num_samples
    num_continuous = 4; num_categorical = 12
    assert opts.latent_dim == num_continuous + num_categorical
    
    z_continuous = torch.rand(B, k, num_continuous, device=opts.device) * 2 - 1
    indices = torch.randint(0, num_categorical, (B, k), device=opts.device)
    z_categorical = F.one_hot(indices, num_classes=num_categorical).float()
    z = torch.cat([z_continuous, z_categorical], dim=-1)

    x_expanded = Batch.from_data_list([instance for _ in range(k)])
    z_reshaped = z.view(B * k, opts.latent_dim)
    
    with torch.no_grad():
        costs, _, pis = model(x_expanded, z_reshaped, return_pi=True)
    
    best_idx = torch.argmin(costs)
    best_cost = costs[best_idx].item()
    best_pi_indices = pis[best_idx].cpu().numpy()
    
    # --- 6. ìµœì¢… ê²°ê³¼ë¥¼ ì¸ë±ìŠ¤ì—ì„œ ë‹¤ì‹œ ë ˆì´ë¸”ë¡œ ë³€í™˜ ---
    final_path_labels = [shopping_list[i] for i in best_pi_indices]
    
    print(f"  [INFO] íƒìƒ‰ ì™„ë£Œ. ìµœì  ë¹„ìš©: {best_cost:.4f}")
    
    return final_path_labels