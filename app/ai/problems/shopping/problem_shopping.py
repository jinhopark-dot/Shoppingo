from torch.utils.data import Dataset
import torch
import os
import pickle
import numpy as np
from .state_shopping import StateShopping
from scipy.spatial.distance import pdist, squareform
from torch_geometric.data import Data

def generate_pyg_instance(graph_size, edge_index, noise_factor=5, noise_probability=0.3):
    """
    ì‚¬ì „ ê³„ì‚°ëœ edge_indexë¥¼ ì‚¬ìš©í•˜ì—¬ PyG Data ê°ì²´ë¥¼ ë¹ ë¥´ê²Œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # 1ë‹¨ê³„ ~ 5ë‹¨ê³„: ì´ ë¶€ë¶„ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ë§¤ìš° ë¹ ë¦…ë‹ˆë‹¤.
    node_coords = np.random.uniform(0, 50, size=(graph_size, 2))
    euclidean_dist_matrix = squareform(pdist(node_coords, 'euclidean'))
    upper_triangle_indices = np.triu_indices(graph_size, k=1)
    num_upper_triangle_edges = len(upper_triangle_indices[0])
    num_noisy_edges = int(num_upper_triangle_edges * noise_probability)
    potential_noise = 1 + np.random.uniform(0, noise_factor, size=num_upper_triangle_edges)
    indices_to_apply_noise = np.random.choice(num_upper_triangle_edges, num_noisy_edges, replace=False)
    noise_multipliers = np.ones(num_upper_triangle_edges)
    noise_multipliers[indices_to_apply_noise] = potential_noise[indices_to_apply_noise]
    noise_matrix = np.ones((graph_size, graph_size))
    noise_matrix[upper_triangle_indices] = noise_multipliers
    noise_matrix.T[upper_triangle_indices] = noise_multipliers
    dist_matrix = torch.FloatTensor(euclidean_dist_matrix * noise_matrix)

    start_idx, end_idx = np.random.choice(graph_size, 2, replace=False)

    # --- ğŸ”‘ 6ë‹¨ê³„: ë” ì´ìƒ edge_indexë¥¼ ìƒì„±í•˜ì§€ ì•Šê³ , ë°”ë¡œ ì‚¬ìš© ---
    edge_attr = dist_matrix[edge_index[0], edge_index[1]].unsqueeze(1)

    return Data(
        edge_index=edge_index,
        edge_attr=edge_attr,
        node_coords=torch.FloatTensor(node_coords),
        dist_matrix=dist_matrix,
        start_idx=torch.tensor(start_idx, dtype=torch.long),
        end_idx=torch.tensor(end_idx, dtype=torch.long),
        num_nodes=graph_size
    )


class Shopping(object):
    NAME = 'shopping'
    
    # ==============================================================================
    #      ìµœì¢…ì ìœ¼ë¡œ ìˆ˜ì •ëœ get_costs í•¨ìˆ˜ (ë²¡í„°í™” + ë…¼ë¦¬ ì˜¤ë¥˜ ìˆ˜ì •)
    # ==============================================================================
    @staticmethod
    def get_costs(dataset, pi):
        """
        íˆ¬ì–´ ë¹„ìš© ê³„ì‚° (ë²¡í„°í™”ëœ ìµœì¢… ë²„ì „)
        piëŠ” ëª¨ë¸ì´ ì¶œë ¥í•œ ì „ì²´ ê²½ë¡œì…ë‹ˆë‹¤. (ì‹œì‘ ë…¸ë“œ í¬í•¨)
        """
        dist_matrix = dataset['dist_matrix']
        batch_size, graph_size = pi.size()

        # 1. ê²½ë¡œ ë¹„ìš© ê³„ì‚° (pi[0]->pi[1]->...->pi[n-1])
        batch_idx = torch.arange(batch_size, device=pi.device).unsqueeze(1)
        from_nodes = pi[:, :-1]
        to_nodes = pi[:, 1:]
        
        path_costs = dist_matrix[batch_idx.expand_as(from_nodes), from_nodes, to_nodes].sum(dim=1)

        # 2. ìˆœíšŒ ë¬¸ì œ(start==end)ì¸ ê²½ìš°, ë§ˆì§€ë§‰ ë…¸ë“œì—ì„œ ì‹œì‘ ë…¸ë“œë¡œ ëŒì•„ì˜¤ëŠ” ë¹„ìš© ì¶”ê°€
        start_idx = dataset['start_idx']
        end_idx = dataset['end_idx']
        
        # ìˆœíšŒ ë¬¸ì œì— í•´ë‹¹í•˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ì˜ ë§ˆìŠ¤í¬ ìƒì„±
        is_tour_mask = (start_idx == end_idx)
        
        if is_tour_mask.any():
            # ìˆœíšŒ ë¬¸ì œì¸ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ì„œë§Œ ë§ˆì§€ë§‰ ë…¸ë“œì™€ ì‹œì‘ ë…¸ë“œë¥¼ ê°€ì ¸ì˜´
            last_nodes = pi[is_tour_mask, -1]
            start_nodes_of_tour = start_idx[is_tour_mask]
            batch_idx_of_tour = torch.arange(is_tour_mask.sum(), device=pi.device)
            
            # ëŒì•„ì˜¤ëŠ” ë¹„ìš© ê³„ì‚°
            return_costs = dist_matrix[is_tour_mask, last_nodes, start_nodes_of_tour]
            
            # ì „ì²´ ë¹„ìš©ì— ëŒì•„ì˜¤ëŠ” ë¹„ìš©ì„ ë”í•´ì¤Œ
            path_costs[is_tour_mask] += return_costs

        return path_costs, None

    @staticmethod
    def make_dataset(*args, **kwargs):
        return ShoppingDataset(*args, **kwargs)
    
    @staticmethod
    def make_state(*args, **kwargs):
        return StateShopping.initialize(*args, **kwargs)

class ShoppingDataset(Dataset):
    def __init__(self, size=30, num_samples=10000, **kwargs):
        super(ShoppingDataset, self).__init__()
        
        print(f"Generating {num_samples} PyG shopping instances...")

        # --- ğŸ”‘ 1. edge_indexë¥¼ ë‹¨ í•œ ë²ˆë§Œ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤ ---
        adj = torch.ones((size, size)) - torch.eye(size)
        self.edge_index = adj.nonzero(as_tuple=False).t().contiguous()
        
        self.data = []
        for i in range(num_samples):
            if (i + 1) % 1000 == 0:
                print(f"  Generated {i + 1}/{num_samples} instances")
            
            # --- ğŸ”‘ 2. ì‚¬ì „ ê³„ì‚°ëœ edge_indexë¥¼ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤ ---
            self.data.append(
                generate_pyg_instance(
                    graph_size=size,
                    edge_index=self.edge_index,
                    **kwargs
                )
            )
            
        self.size = len(self.data)
        print("Dataset generation complete!")
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        return self.data[idx]

